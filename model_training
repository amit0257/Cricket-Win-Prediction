# importing train_test_split
from sklearn.model_selection import train_test_split

X=df1.drop('Result',axis=1)
y=df1['Result']

y=y.astype('int')

# split into 70:30 ration
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

# describes info about train and test set
print("Number transactions X_train dataset: ", X_train.shape)
print("Number transactions y_train dataset: ", y_train.shape)
print("Number transactions X_test dataset: ", X_test.shape)
print("Number transactions y_test dataset: ", y_test.shape)

from collections import Counter
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE

counter=Counter(y)
counter

from imblearn.over_sampling import SMOTE

oversample = SMOTE()
X, y = oversample.fit_resample(X, y)

counter=Counter(y)
counter

"""# Lets apply Machine Learning modules to see the preidction

"""

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.metrics import confusion_matrix,classification_report,roc_auc_score,roc_curve
from sklearn import metrics

clf = LinearDiscriminantAnalysis()
model1=clf.fit(X_train,y_train)
model1

y_train_predict=model1.predict(X_train)
model_score=model1.score(X_train, y_train)
print(model_score)
print('  ')
print(metrics.confusion_matrix(y_train,y_train_predict))
print('  ')

print(metrics.classification_report(y_train,y_train_predict))

from sklearn.metrics import roc_auc_score,roc_curve

probs_train=model1.predict_proba(X_train)
probs_train=probs_train[:, 1]
auc=roc_auc_score(y_train,probs_train)
print("the auc %.3f " % auc)
train_fpr ,train_tpr, train_thresholds= roc_curve(y_train,probs_train)
plt.plot([0,1],[0,1],linestyle='--')
plt.plot(train_fpr,train_tpr);

importance = model1.coef_[0]
# summarize feature importance
for i,v in enumerate(importance):
	print('Feature: %0d, Score: %.5f' % (i,v))
# plot feature importance
sns.barplot([x for x in range(len(importance))], importance)
plt.show()

X.info()

y_test_predict=model1.predict(X_test)
model_score=model1.score(X_test, y_test)
print(model_score)
print(metrics.confusion_matrix(y_test,y_test_predict))

print(metrics.classification_report(y_test,y_test_predict))

probs_test=model1.predict_proba(X_test)
probs_test=probs_test[:,1]
auc=roc_auc_score(y_test,probs_test)
print("the auc curve %.3f " % auc)

test_fpr,test_tpr,test_threshold=roc_curve(y_test,probs_test)
plt.plot([0,1],[0,1],linestyle='--')
plt.plot(test_fpr, test_tpr)

"""Naive Bayes"""

from sklearn.naive_bayes import GaussianNB

NB=GaussianNB()
model2=NB.fit(X_train, y_train)

y_train_predict=model2.predict(X_train)
model_score=model2.score(X_train, y_train)
print(model_score)
print('  ')
print(metrics.confusion_matrix(y_train,y_train_predict))
print('  ')

print(metrics.classification_report(y_train,y_train_predict))

probs_train=model2.predict_proba(X_train)
probs_train=probs_train[:, 1]
auc=roc_auc_score(y_train,probs_train)
print("the auc %.3f " % auc)
train_fpr ,train_tpr, train_thresholds= roc_curve(y_train,probs_train)
plt.plot([0,1],[0,1],linestyle='--')
plt.plot(train_fpr,train_tpr);

y_test_predict=model2.predict(X_test)
model_score=model2.score(X_test, y_test)
print(model_score)
print(metrics.confusion_matrix(y_test,y_test_predict))

print(metrics.classification_report(y_test,y_test_predict))

probs_test=model2.predict_proba(X_test)
probs_test=probs_test[:,1]
auc=roc_auc_score(y_test,probs_test)
print("the auc curve %.3f " % auc)

test_fpr,test_tpr,test_threshold=roc_curve(y_test,probs_test)
plt.plot([0,1],[0,1],linestyle='--')
plt.plot(test_fpr, test_tpr)

"""KNN"""

from sklearn.neighbors import KNeighborsClassifier

KNN_model=KNeighborsClassifier()
model3=KNN_model.fit(X_train,y_train)

y_train_predict=model3.predict(X_train)
model_score=model3.score(X_train, y_train)
print(model_score)
print('  ')
print(metrics.confusion_matrix(y_train,y_train_predict))
print('  ')

print(metrics.classification_report(y_train,y_train_predict))

probs_train=model3.predict_proba(X_train)
probs_train=probs_train[:, 1]
auc=roc_auc_score(y_train,probs_train)
print("the auc %.3f " % auc)
train_fpr ,train_tpr, train_thresholds= roc_curve(y_train,probs_train)
plt.plot([0,1],[0,1],linestyle='--')
plt.plot(train_fpr,train_tpr);

y_test_predict=model3.predict(X_test)
model_score=model3.score(X_test, y_test)
print(model_score)
print(metrics.confusion_matrix(y_test,y_test_predict))

print(metrics.classification_report(y_test,y_test_predict))

probs_test=model3.predict_proba(X_test)
probs_test=probs_test[:,1]
auc=roc_auc_score(y_test,probs_test)
print("the auc curve %.3f " % auc)

test_fpr,test_tpr,test_threshold=roc_curve(y_test,probs_test)
plt.plot([0,1],[0,1],linestyle='--')
plt.plot(test_fpr, test_tpr)

"""# Decision Tree

"""

from sklearn import tree

DT_model=tree.DecisionTreeClassifier(max_depth=8, random_state=42)
model4=DT_model.fit(X_train,y_train)

y_train_predict=model4.predict(X_train)
model_score=model4.score(X_train, y_train)
print(model_score)
print('  ')
print(metrics.confusion_matrix(y_train,y_train_predict))
print('  ')

print(metrics.classification_report(y_train,y_train_predict))

probs_train=model4.predict_proba(X_train)
probs_train=probs_train[:, 1]
auc=roc_auc_score(y_train,probs_train)
print("the auc %.3f " % auc)
train_fpr ,train_tpr, train_thresholds= roc_curve(y_train,probs_train)
plt.plot([0,1],[0,1],linestyle='--')
plt.plot(train_fpr,train_tpr);

y_test_predict=model4.predict(X_test)
model_score=model4.score(X_test, y_test)
print(model_score)
print(metrics.confusion_matrix(y_test,y_test_predict))

print(metrics.classification_report(y_test,y_test_predict))

probs_test=model4.predict_proba(X_test)
probs_test=probs_test[:,1]
auc=roc_auc_score(y_test,probs_test)
print("the auc curve %.3f " % auc)

test_fpr,test_tpr,test_threshold=roc_curve(y_test,probs_test)
plt.plot([0,1],[0,1],linestyle='--')
plt.plot(test_fpr, test_tpr)

importance = model4.feature_importances_
# summarize feature importance
for i,v in enumerate(importance):
	print('Feature: %0d, Score: %.5f' % (i,v))
# plot feature importance
sns.barplot([x for x in range(len(importance))], importance)
plt.show()

"""# Ensemble Methods

## Random Forrest
"""

from sklearn.ensemble import RandomForestClassifier

rf_model=RandomForestClassifier()
model5=rf_model.fit(X_train,y_train)

y_train_predict=model5.predict(X_train)
model_score=model5.score(X_train, y_train)
print(model_score)
print('  ')
print(metrics.confusion_matrix(y_train,y_train_predict))
print('  ')

print(metrics.classification_report(y_train,y_train_predict))

importance = model5.feature_importances_
# summarize feature importance
for i,v in enumerate(importance):
	print('Feature: %0d, Score: %.5f' % (i,v))
# plot feature importance
sns.barplot([x for x in range(len(importance))], importance)
plt.show()

y_test_predict=model5.predict(X_test)
model_score=model5.score(X_test, y_test)
print(model_score)
print(metrics.confusion_matrix(y_test,y_test_predict))

print(metrics.classification_report(y_test,y_test_predict))

probs_train=model5.predict_proba(X_train)
probs_train=probs_train[:, 1]
auc=roc_auc_score(y_train,probs_train)
print("the auc for train %.3f " % auc)

probs_test=model5.predict_proba(X_test)
probs_test=probs_test[:,1]
auc=roc_auc_score(y_test,probs_test)
print("the auc for test %.3f " % auc)

from sklearn.model_selection import GridSearchCV

param_grid = {  'bootstrap': [True], 'max_depth': [5, 10, None], 'max_features': ['auto', 'log2'], 'n_estimators': [5, 6, 7, 8, 9, 10, 11, 12, 13, 15]}

g_search_RF = GridSearchCV(estimator = rf_model, param_grid = param_grid,

                          cv = 3, n_jobs = 1, verbose = 0, return_train_score=True)

rf_tuned=g_search_RF.fit(X_train,y_train)

y_train_predict=rf_tuned.predict(X_train)
model_score=rf_tuned.score(X_train, y_train)
print(model_score)
print('  ')
print(metrics.confusion_matrix(y_train,y_train_predict))
print('  ')

print(metrics.classification_report(y_train,y_train_predict))

y_test_predict=rf_tuned.predict(X_test)
model_score=rf_tuned.score(X_test, y_test)
print(model_score)
print(metrics.confusion_matrix(y_test,y_test_predict))

print(metrics.classification_report(y_test,y_test_predict))

probs_train=rf_tuned.predict_proba(X_train)
probs_train=probs_train[:, 1]
auc=roc_auc_score(y_train,probs_train)
print("the auc %.3f " % auc)

probs_test=rf_tuned.predict_proba(X_test)
probs_test=probs_test[:,1]
auc=roc_auc_score(y_test,probs_test)
print("the auc curve %.3f " % auc)



"""## Bagging Classifier"""

from sklearn.ensemble import BaggingClassifier

bgcl = BaggingClassifier(n_estimators=100,random_state=1)

model6 = bgcl.fit(X_train, y_train)

y_train_predict=model6.predict(X_train)
model_score=model6.score(X_train, y_train)
print(model_score)
print('  ')
print(metrics.confusion_matrix(y_train,y_train_predict))
print('  ')

print(metrics.classification_report(y_train,y_train_predict))

y_test_predict=model6.predict(X_test)
model_score=model6.score(X_test, y_test)
print(model_score)
print(metrics.confusion_matrix(y_test,y_test_predict))

print(metrics.classification_report(y_test,y_test_predict))

probs_train=model6.predict_proba(X_train)
probs_train=probs_train[:, 1]
auc=roc_auc_score(y_train,probs_train)
print("the auc for train %.3f " % auc)

probs_test=model6.predict_proba(X_test)
probs_test=probs_test[:,1]
auc=roc_auc_score(y_test,probs_test)
print("the auc for test %.3f " % auc)

"""Model Tuning for Bagging"""

param_grid = {
    'base_estimator__max_depth' : [1, 2, 3, 4, 5],
    'max_samples' : [0.05, 0.1, 0.2, 0.5]
}

clf = GridSearchCV(BaggingClassifier(RandomForestClassifier(),
                                     n_estimators = 100, max_features = 0.5 ),
                   param_grid)
bc_tned= clf.fit(X_train, y_train)

print(clf.best_params_)

y_train_predict=bc_tned.predict(X_train)
model_score=bc_tned.score(X_train, y_train)
print(model_score)
print('  ')
print(metrics.confusion_matrix(y_train,y_train_predict))
print('  ')

print(metrics.classification_report(y_train,y_train_predict))

y_test_predict=bc_tned.predict(X_test)
model_score=bc_tned.score(X_test, y_test)
print(model_score)
print(metrics.confusion_matrix(y_test,y_test_predict))

print(metrics.classification_report(y_test,y_test_predict))

probs_train=bc_tned.predict_proba(X_train)
probs_train=probs_train[:, 1]
auc=roc_auc_score(y_train,probs_train)
print("the auc for train %.3f " % auc)

probs_test=bc_tned.predict_proba(X_test)
probs_test=probs_test[:,1]
auc=roc_auc_score(y_test,probs_test)
print("the auc for test %.3f " % auc)

"""## ADA BOOSTING"""

from sklearn.ensemble import AdaBoostClassifier

clfADB = AdaBoostClassifier(n_estimators=100)
model7=clfADB.fit(X_train,y_train)

y_train_predict=model7.predict(X_train)
model_score=model7.score(X_train, y_train)
print(model_score)
print('  ')
print(metrics.confusion_matrix(y_train,y_train_predict))
print('  ')

print(metrics.classification_report(y_train,y_train_predict))

importance = model7.feature_importances_
# summarize feature importance
for i,v in enumerate(importance):
	print('Feature: %0d, Score: %.5f' % (i,v))
# plot feature importance
sns.barplot([x for x in range(len(importance))], importance)
plt.show()

y_test_predict=model7.predict(X_test)
model_score=model7.score(X_test, y_test)
print(model_score)
print(metrics.confusion_matrix(y_test,y_test_predict))

print(metrics.classification_report(y_test,y_test_predict))

probs_train=model7.predict_proba(X_train)
probs_train=probs_train[:, 1]
auc=roc_auc_score(y_train,probs_train)
print("the auc for train %.3f " % auc)

probs_test=model7.predict_proba(X_test)
probs_test=probs_test[:,1]
auc=roc_auc_score(y_test,probs_test)
print("the auc for test %.3f " % auc)

"""## Gradient Bossting"""

from sklearn.ensemble import GradientBoostingClassifier
gbcl = GradientBoostingClassifier(n_estimators = 50,random_state=1)
model8 = gbcl.fit(X_train, y_train)

y_train_predict=model8.predict(X_train)
model_score=model8.score(X_train, y_train)
print(model_score)
print('  ')
print(metrics.confusion_matrix(y_train,y_train_predict))
print('  ')

print(metrics.classification_report(y_train,y_train_predict))

importance = model8.feature_importances_
# summarize feature importance
for i,v in enumerate(importance):
	print('Feature: %0d, Score: %.5f' % (i,v))
# plot feature importance
sns.barplot([x for x in range(len(importance))], importance)
plt.show()

y_test_predict=model8.predict(X_test)
model_score=model8.score(X_test, y_test)
print(model_score)
print(metrics.confusion_matrix(y_test,y_test_predict))

print(metrics.classification_report(y_test,y_test_predict))
